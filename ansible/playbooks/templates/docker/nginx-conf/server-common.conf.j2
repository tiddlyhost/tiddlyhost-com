#
# A few common requests that we don't want to pass through to rails
#
location = /ads.txt { return 404; }

# Todo somehow: We want /store.php (only) to be proxied the same as @app
location ~ \.(?:php|jsp|asp|aspx|env|sql)(?:$|\?) { return 404; access_log off; }
location ~ \.sql\.(?:xz|zip|z|gz)(?:$|\?) { return 404; access_log off; }
location ~ /wlwmanifest\.xml(?:$|\?) { return 404; access_log off; }
location ~ \.git/(?:config|HEAD) { return 404; access_log off; }
location ~ /wp-admin/ { return 404; access_log off; }
location ~ /wp-includes/ { return 404; access_log off; }
location ~ /wp-content/ { return 404; access_log off; }
location ~ /wp-plugins/ { return 404; access_log off; }
location ~ /\.well-known/ { return 404; access_log off; }
location ~ ^/core/modules/ { return 404; access_log off; }
location ~ ^/plugins/ { return 404; access_log off; }
location ~ ^/.env { return 404; access_log off; }
location ~ ^/phpinfo { return 404; access_log off; }
location ~ ^/_profiler { return 404; access_log off; }

location ~ ^/_ts_ { return 404; access_log off; }
location ~ ^/_ts/ { return 404; access_log off; }
location ~ ^/_sites/ { return 404; access_log off; }

location = /sitemap.xml { return 404; access_log off; }
location = /index.xml { return 404; access_log off; }

#
# Block explore tag/user URLs when accessed without referrer. Why?
# So many crawlers are ignoring robots.txt and crawling these urls
# endlessly, which eats up our CPU since the explore pages are quite
# heavy. Most of them don't set a referrer, so let's try this as a
# way to block that traffic.
#
# We will allow the "primary" /explore/tag/foo and /explore/user/foo
# since maybe they are useful bookmarks, but we'll block if there are
# any additional url params (other than the special "t=1" which is
# present for all the /templates urls.)
#
location ~ ^/(?:templates|explore)/(?:tag|user)/ {
    set $checks "";
    # An alternative more restrictive idea for the referer:
    #if ($http_referer !~ {{ primary_host }}) {
    if ($http_referer = "") {
        # No referer implies it might be a bot,
        # (but it could also be from a bookmark)
        set $checks "${checks}x";
    }
    if ($args != "") {
        # There are some url params present
        set $checks "${checks}x";
    }
    if ($args != "t=1") {
        # There are params present other than the one special t=1
        # param which is always there for /templates urls
        set $checks "${checks}x";
    }
    if ($checks = "xxx") {
        # If all three of the above are true, you are
        # considered delinquint crawler, please go away
        return 404;
    }

    #
    # Fixme: For some reason `try_files $uri @app` does not work here. All this
    # is identical to the location @app block. Should refactor so we are not
    # repeating code from the location @app block, or figure out why try_files
    # won't work. (Actually it might be that it works in production but not in
    # local development, maybe related to the /opt/rails-static volume.)
    #
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_redirect off;
    proxy_pass http://app:3333;
}

#
# Avoid '413 Request Entity Too Large' when saving TiddlyWikis.
# Using 0 here means unlimited, but I'm thinking some kind of limit
# is probably a good idea. 200m seems large enough. A new site is 2m.
#
client_max_body_size 200m;

#
# In production this is a volume mounting #{Rails.root}/public from the
# rails app container. If the request matches a static file there, serve
# it directly, otherwise pass the request through to rails. (In development
# it won't exist so everything will be passed through to rails. Todo maybe:
# change that.)
#
root /opt/rails-static;

location / {
  # Static assets served directly
  try_files $uri @app;
}

# The more specific match should take precedence over the above
location ~ ^/(assets/|packs/|tiddlywikicore-|) {
  # Let nginx know it can use the static gz files
  gzip_static on;
  # Static assets served directly that can be cached forever
  expires max;
  add_header Cache-Control "public";
  try_files $uri @app;
}

#
# Proxy everything else through to the rails app
#
location @app {
  #
  # The rails application cares about all this so make
  # sure it knows the real request details
  #
  proxy_set_header Host $host;
  proxy_set_header X-Forwarded-Proto $scheme;
  proxy_set_header X-Real-IP $remote_addr;

  #
  # Not sure what these do...
  #
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  proxy_redirect off;

  #
  # The rails app is here
  #
  proxy_pass http://app:3333;
}

#
# The default "bad gateway" page is not very nice so let's use
# a custom page. Should appear if the @app container is down.
#
error_page 502 /custom502.html;
location = /custom502.html {
  root /opt/nginx-html;
  internal;
}
